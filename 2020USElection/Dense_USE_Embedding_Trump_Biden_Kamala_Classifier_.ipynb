{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dense - USE Embedding Trump Biden Kamala Classifier .ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YlqH2zH7pqLe"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sljm12/Programming-exploration/blob/master/2020USElection/Dense_USE_Embedding_Trump_Biden_Kamala_Classifier_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMg9tEpwxP1Z"
      },
      "source": [
        "## Intro ##\n",
        "This notebook uses LSTM and Dense layers to do speaker identification based on the US election speeches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU4_R09CaDPM"
      },
      "source": [
        "!pip3 install tensorflow_text>=2.0.0rc0"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHRvF17C7vjB"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text\n",
        "\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import json\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxsPFuahqc0e",
        "outputId": "f3ebd103-71ed-4361-f7c5-e0cb86b30f94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        }
      },
      "source": [
        "!wget https://www.dropbox.com/s/fna7obll05a8dmi/2020USElection.zip\n",
        "!unzip 2020USElection.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-23 12:02:49--  https://www.dropbox.com/s/fna7obll05a8dmi/2020USElection.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.1, 2620:100:6016:1::a27d:101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/fna7obll05a8dmi/2020USElection.zip [following]\n",
            "--2020-10-23 12:02:49--  https://www.dropbox.com/s/raw/fna7obll05a8dmi/2020USElection.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucf472704af420100da831cafc2c.dl.dropboxusercontent.com/cd/0/inline/BBwMqLvobXhBdfcYvccS38OEwjfGR0UCY52yHIz1X7xYdqChJ12RrjPup01k4wyo8ZIGJ4SKxt2lVWEQe23JJN8ATFi0LXo9ftpThMrMO_mMmYfOxvfX39fW7ZRyLYxmpCg/file# [following]\n",
            "--2020-10-23 12:02:50--  https://ucf472704af420100da831cafc2c.dl.dropboxusercontent.com/cd/0/inline/BBwMqLvobXhBdfcYvccS38OEwjfGR0UCY52yHIz1X7xYdqChJ12RrjPup01k4wyo8ZIGJ4SKxt2lVWEQe23JJN8ATFi0LXo9ftpThMrMO_mMmYfOxvfX39fW7ZRyLYxmpCg/file\n",
            "Resolving ucf472704af420100da831cafc2c.dl.dropboxusercontent.com (ucf472704af420100da831cafc2c.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to ucf472704af420100da831cafc2c.dl.dropboxusercontent.com (ucf472704af420100da831cafc2c.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BBxHGOXs2EPleuDf3l0UVAQPI3BN9mHrzfBKUxifuunuxpSykzua1-vfdq78SW_NZ_Q8mAmT5DUFxuceBhhBlQFBTQfcbAUcZ3BWFSYJGv81YxSjTrklSa1OgUFtaemq3Wn1I89G93i9ayeAOkL3O676PlXy2G7vo9EcMOkNEooibRSFB1yiEGbToBdysY5iNwVYwUZa7tOi2oHlmCN6yfUB2egn0-nM2zCY7L9qZYaR98TsQYW_XSNy5kPItTwQHkzIvK11KqRc4X0GE9iL0gNAW2c0ftDCfxZrDexkMez5bZBWUnb8mt23Lni18DoZhScZfwMnLv5lnJPXU8E87O416bW6veC-LuDoeusKrlw2yg/file [following]\n",
            "--2020-10-23 12:02:50--  https://ucf472704af420100da831cafc2c.dl.dropboxusercontent.com/cd/0/inline2/BBxHGOXs2EPleuDf3l0UVAQPI3BN9mHrzfBKUxifuunuxpSykzua1-vfdq78SW_NZ_Q8mAmT5DUFxuceBhhBlQFBTQfcbAUcZ3BWFSYJGv81YxSjTrklSa1OgUFtaemq3Wn1I89G93i9ayeAOkL3O676PlXy2G7vo9EcMOkNEooibRSFB1yiEGbToBdysY5iNwVYwUZa7tOi2oHlmCN6yfUB2egn0-nM2zCY7L9qZYaR98TsQYW_XSNy5kPItTwQHkzIvK11KqRc4X0GE9iL0gNAW2c0ftDCfxZrDexkMez5bZBWUnb8mt23Lni18DoZhScZfwMnLv5lnJPXU8E87O416bW6veC-LuDoeusKrlw2yg/file\n",
            "Reusing existing connection to ucf472704af420100da831cafc2c.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7288468 (7.0M) [application/zip]\n",
            "Saving to: ‘2020USElection.zip’\n",
            "\n",
            "2020USElection.zip  100%[===================>]   6.95M  39.5MB/s    in 0.2s    \n",
            "\n",
            "2020-10-23 12:02:51 (39.5 MB/s) - ‘2020USElection.zip’ saved [7288468/7288468]\n",
            "\n",
            "Archive:  2020USElection.zip\n",
            "  inflating: 2020USElection-BreakSentence.csv  \n",
            "  inflating: 2020USElectiontop5.csv  \n",
            "  inflating: 2020USElectionTranscript.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrjiL7cAvPXy"
      },
      "source": [
        "# Prepping the data ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9a4H8P2Z3-k"
      },
      "source": [
        "df = pd.read_csv(\"/content/2020USElection-BreakSentence.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoiYHFTAabkm",
        "outputId": "c7d1b9e1-e86b-415a-c503-bc1bfdd1f378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>name</th>\n",
              "      <th>file</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Bernie Sanders</td>\n",
              "      <td>2020 Democratic National Convention (DNC) Nigh...</td>\n",
              "      <td>We must come together to defeat Donald Trump, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Joe Biden</td>\n",
              "      <td>2020 Democratic National Convention (DNC) Nigh...</td>\n",
              "      <td>I’ll see you on Thursday.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Kamala Harris</td>\n",
              "      <td>2020 Democratic National Convention (DNC) Nigh...</td>\n",
              "      <td>In this election, we have a chance to change t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Kamala Harris</td>\n",
              "      <td>2020 Democratic National Convention (DNC) Nigh...</td>\n",
              "      <td>We’re all in this fight together.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Kamala Harris</td>\n",
              "      <td>2020 Democratic National Convention (DNC) Nigh...</td>\n",
              "      <td>What an awesome responsibility.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                               text\n",
              "0           0  ...  We must come together to defeat Donald Trump, ...\n",
              "1           1  ...                          I’ll see you on Thursday.\n",
              "2           2  ...  In this election, we have a chance to change t...\n",
              "3           3  ...                  We’re all in this fight together.\n",
              "4           4  ...                    What an awesome responsibility.\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2-BDz5u_CAu",
        "outputId": "832633d8-18a7-492e-9429-0536728420ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "df[\"text\"].values"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['We must come together to defeat Donald Trump, and elect Joe Biden and Kamala Harris as our next President and Vice President.',\n",
              "       'I’ll see you on Thursday.',\n",
              "       'In this election, we have a chance to change the course of history.',\n",
              "       ..., 'We’re going to be in Detroit Monday night.',\n",
              "       'Come join us Monday night.', 'I’ll see you later.'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GadvqCTEz2wa"
      },
      "source": [
        "## One Hot Encoding of Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9lSZVynadU9"
      },
      "source": [
        "names = df[\"name\"].unique()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkVgLzkBYcdZ"
      },
      "source": [
        "num_categories = len(names)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_peqdAe5DK3"
      },
      "source": [
        "i, m = pd.factorize(df[\"name\"])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENZ1-H7A1dFp"
      },
      "source": [
        "df[\"cat_num\"]=i"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wMCXDkG5KQN"
      },
      "source": [
        "labels = tf.one_hot(i, depth=len(m))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SO272amgfIE"
      },
      "source": [
        "(train_df, others)=train_test_split(df,shuffle=True,test_size=0.4, stratify=df['name'])\n",
        "(val_df, test_df)=train_test_split(others,shuffle=True,test_size=0.5, stratify=others['name'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za8YNFhWyxR4",
        "outputId": "984dc35f-07a5-4b49-92fa-54ef74600390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(len(train_df))\n",
        "print(len(val_df))\n",
        "print(len(test_df))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53659\n",
            "17887\n",
            "17887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdaB2sdPqp2k"
      },
      "source": [
        "X_train = train_df[\"text\"].astype(str).values\n",
        "y_train = tf.one_hot(train_df[\"cat_num\"], num_categories)\n",
        "X_val = val_df[\"text\"].astype(str).values\n",
        "y_val = tf.one_hot(val_df[\"cat_num\"], num_categories)\n",
        "X_test = test_df[\"text\"].astype(str).values\n",
        "y_test= tf.one_hot(test_df[\"cat_num\"], num_categories)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy4d1XhGempN"
      },
      "source": [
        "# TF Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB0mSmenIaoC"
      },
      "source": [
        "## Tokenizer the text ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AytbBqsmY6X"
      },
      "source": [
        "max_len =100\n",
        "max_features = 20000\n",
        "batch_size=64\n",
        "dims=50"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpgEvSIOpkq3"
      },
      "source": [
        "## Token ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7t62hj4qp4l"
      },
      "source": [
        "t=Tokenizer()\n",
        "t.fit_on_texts(df[\"text\"].astype(str).values)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bM844h84hbFn"
      },
      "source": [
        "#Pad Data\n",
        "text_encode = t.texts_to_sequences(X_train) #Encode the text\n",
        "x_train_pad=pad_sequences(maxlen=max_len, sequences=text_encode, padding=\"post\", value=0)\n",
        "\n",
        "val_encode = t.texts_to_sequences(X_val) #Encode the text\n",
        "x_val_pad=pad_sequences(maxlen=max_len, sequences=val_encode, padding=\"post\", value=0)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZDCtofcxepv"
      },
      "source": [
        "test_encode = t.texts_to_sequences(X_test)\n",
        "x_test_pad=pad_sequences(maxlen=max_len,sequences=test_encode,padding='post',value=0)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt_MedX4JF9a",
        "outputId": "8d51ceff-d547-406a-fe43-e69696ec36f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "import json\n",
        "print(X_train[0])\n",
        "print(text_encode[0])\n",
        "t_config = t.get_config()\n",
        "\n",
        "print(t_config.keys())\n",
        "\n",
        "word_index=json.loads(t_config[\"word_index\"])\n",
        "index_word=json.loads(t_config[\"index_word\"])\n",
        "n_words=len(word_index.keys())\n",
        "print(n_words)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "President Donald Trump is the most pro-life president in American history, it’s true.\n",
            "[45, 184, 103, 14, 1, 164, 989, 206, 45, 8, 76, 177, 26, 317]\n",
            "dict_keys(['num_words', 'filters', 'lower', 'split', 'char_level', 'oov_token', 'document_count', 'word_counts', 'word_docs', 'index_docs', 'index_word', 'word_index'])\n",
            "16445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0XlkbOBhg3e",
        "outputId": "894d76e5-c649-4c81-edca-f0e698d272ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(x_train_pad[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlqH2zH7pqLe"
      },
      "source": [
        "## Complicated Way ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-k7hq8gsuDt"
      },
      "source": [
        "words = set()\n",
        "\n",
        "for x in X_train:\n",
        "  s=text_to_word_sequence(x)\n",
        "  [words.add(i) for i in s]\n",
        "\n",
        "words.add(\"<ENDTok>\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssqpV-AYrV7v"
      },
      "source": [
        "word2idx = {w: i for i, w in enumerate(words)}\n",
        "idx2word = {i: w for w, i in word2idx.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CEqAVSJqsiD"
      },
      "source": [
        "encode = [[word2idx[tup] for tup in text_to_word_sequence(s)] for s in X_train]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqT28_46uvpm",
        "outputId": "de8925ca-9961-4e30-c57c-620b827833df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(len(encoded[0]),len(text_to_word_sequence(X_train[0])))\n",
        "print(word2idx[\"<ENDTok>\"])\n",
        "print(encoded[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "47 47\n",
            "130783\n",
            "[196714, 185833, 64440, 111005, 186474, 173023, 61657, 47846, 76658, 98757, 166467, 17638, 121582, 21216, 85786, 155699, 185877, 209583, 14548, 167721, 18175, 190516, 122019, 21667, 16312, 182509, 144284, 19906, 112310, 105622, 21111, 208166, 106211, 64440, 9994, 196605, 64440, 63117, 172630, 79628, 163334, 85048, 7461, 829, 38896, 63136, 168653]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY0W1EZ6vz1H",
        "outputId": "c9b25428-2170-4144-ea78-f557befc8305",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "x_train_pad=pad_sequences(maxlen=max_len, sequences=encode, padding=\"post\", value=word2idx[\"<ENDTok>\"])\n",
        "print(x_train_pad[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[196714 185833  64440 111005 186474 173023  61657  47846  76658  98757\n",
            " 166467  17638 121582  21216  85786 155699 185877 209583  14548 167721\n",
            "  18175 190516 122019  21667  16312 182509 144284  19906 112310 105622\n",
            "  21111 208166 106211  64440   9994 196605  64440  63117 172630  79628\n",
            " 163334  85048   7461    829  38896  63136 168653 130783 130783 130783\n",
            " 130783 130783 130783 130783 130783 130783 130783 130783 130783 130783\n",
            " 130783 130783 130783 130783 130783 130783 130783 130783 130783 130783\n",
            " 130783 130783 130783 130783 130783 130783 130783 130783 130783 130783\n",
            " 130783 130783 130783 130783 130783 130783 130783 130783 130783 130783\n",
            " 130783 130783 130783 130783 130783 130783 130783 130783 130783 130783]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwmpvkh5wC45",
        "outputId": "be828372-89de-4c04-8d42-28d1ddd1fe8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n_words=len(words)\n",
        "print(n_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "210338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmJLwy09aak6"
      },
      "source": [
        "# USE Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_NK4kpzieIn"
      },
      "source": [
        "max_len = 512"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdCvA0Yuac5g"
      },
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/4\", \"https://tfhub.dev/google/universal-sentence-encoder-large/5\", \"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\"]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GY_yM8GDalTD",
        "outputId": "e697974a-af8f-46eb-8441-5a69b016f0de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "use_model = hub.load(module_url)\n",
        "print (\"module %s loaded\" % module_url)\n",
        "def embed(input):\n",
        "  return use_model(input)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn_fl7m4ezW6"
      },
      "source": [
        "x_train_pad = embed(X_train)\n",
        "x_val_pad = embed(X_val)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFpfHqKtZ8zo"
      },
      "source": [
        "x_test_pad = embed(X_test)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3fv97CRfLml",
        "outputId": "7a16158d-f3d2-494e-cbb6-dd526f56fe34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train_pad.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([53659, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Va40PtNewUVe"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24985ZApuror"
      },
      "source": [
        "Inp = Input(shape=(max_len,))\n",
        "\n",
        "#notice the n_words+1 in input_dim, result of using tf tokenizer\n",
        "\n",
        "# x = Embedding(input_dim=n_words+1, output_dim=dims, input_length=max_len)(Inp)\n",
        "# x = Dropout(rate=0.1)(x)\n",
        "x = Dense(256)(Inp)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(128)(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(64)(x)\n",
        "x = Dropout(0.2)(x)\n",
        "#x = Dropout(rate=0.1)(x)\n",
        "\n",
        "# Note that the output layers are given names.\n",
        "toxic_prediction = Dense(num_categories, activation=\"softmax\", name='classify')(x)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbVA9iNn1MOQ",
        "outputId": "da657937-2505-42ee-fca6-43b1a598432d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "np.asarray(y_train)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEG4PAO8urow"
      },
      "source": [
        "model = Model(Inp, [toxic_prediction])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wroFFbtOuroy"
      },
      "source": [
        "model.compile(optimizer=\"adam\", \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jkuzEJmvI_p",
        "outputId": "243c4d98-b425-4f03-e46e-e5d06d09f21f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit( np.array(x_train_pad), \n",
        "                    np.array(y_train),\n",
        "                    batch_size=2048, \n",
        "                    epochs=300, \n",
        "                    validation_data= (np.array(x_val_pad),\n",
        "                        np.array(y_val)),\n",
        "                    verbose=1)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7953 - accuracy: 0.7045 - val_loss: 0.8212 - val_accuracy: 0.6978\n",
            "Epoch 2/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7964 - accuracy: 0.7038 - val_loss: 0.8221 - val_accuracy: 0.6966\n",
            "Epoch 3/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7955 - accuracy: 0.7047 - val_loss: 0.8199 - val_accuracy: 0.6981\n",
            "Epoch 4/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7955 - accuracy: 0.7044 - val_loss: 0.8204 - val_accuracy: 0.6965\n",
            "Epoch 5/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7955 - accuracy: 0.7037 - val_loss: 0.8196 - val_accuracy: 0.6979\n",
            "Epoch 6/300\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.7967 - accuracy: 0.7040 - val_loss: 0.8196 - val_accuracy: 0.6983\n",
            "Epoch 7/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7963 - accuracy: 0.7042 - val_loss: 0.8203 - val_accuracy: 0.6961\n",
            "Epoch 8/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7044 - val_loss: 0.8201 - val_accuracy: 0.6968\n",
            "Epoch 9/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7962 - accuracy: 0.7038 - val_loss: 0.8207 - val_accuracy: 0.6963\n",
            "Epoch 10/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7953 - accuracy: 0.7043 - val_loss: 0.8195 - val_accuracy: 0.6970\n",
            "Epoch 11/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7039 - val_loss: 0.8200 - val_accuracy: 0.6978\n",
            "Epoch 12/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7957 - accuracy: 0.7043 - val_loss: 0.8195 - val_accuracy: 0.6975\n",
            "Epoch 13/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7953 - accuracy: 0.7041 - val_loss: 0.8198 - val_accuracy: 0.6965\n",
            "Epoch 14/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7955 - accuracy: 0.7041 - val_loss: 0.8201 - val_accuracy: 0.6975\n",
            "Epoch 15/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7961 - accuracy: 0.7032 - val_loss: 0.8204 - val_accuracy: 0.6963\n",
            "Epoch 16/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7949 - accuracy: 0.7034 - val_loss: 0.8193 - val_accuracy: 0.6960\n",
            "Epoch 17/300\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.7948 - accuracy: 0.7049 - val_loss: 0.8199 - val_accuracy: 0.6990\n",
            "Epoch 18/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7955 - accuracy: 0.7047 - val_loss: 0.8199 - val_accuracy: 0.6989\n",
            "Epoch 19/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7962 - accuracy: 0.7037 - val_loss: 0.8195 - val_accuracy: 0.6973\n",
            "Epoch 20/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7947 - accuracy: 0.7042 - val_loss: 0.8195 - val_accuracy: 0.6968\n",
            "Epoch 21/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7954 - accuracy: 0.7056 - val_loss: 0.8201 - val_accuracy: 0.6988\n",
            "Epoch 22/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7950 - accuracy: 0.7045 - val_loss: 0.8192 - val_accuracy: 0.6974\n",
            "Epoch 23/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7946 - accuracy: 0.7052 - val_loss: 0.8198 - val_accuracy: 0.6992\n",
            "Epoch 24/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7034 - val_loss: 0.8200 - val_accuracy: 0.6978\n",
            "Epoch 25/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7952 - accuracy: 0.7042 - val_loss: 0.8195 - val_accuracy: 0.6965\n",
            "Epoch 26/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7952 - accuracy: 0.7043 - val_loss: 0.8196 - val_accuracy: 0.6967\n",
            "Epoch 27/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7036 - val_loss: 0.8197 - val_accuracy: 0.6982\n",
            "Epoch 28/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7958 - accuracy: 0.7032 - val_loss: 0.8194 - val_accuracy: 0.6987\n",
            "Epoch 29/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7957 - accuracy: 0.7036 - val_loss: 0.8194 - val_accuracy: 0.6977\n",
            "Epoch 30/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7950 - accuracy: 0.7040 - val_loss: 0.8208 - val_accuracy: 0.6971\n",
            "Epoch 31/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7943 - accuracy: 0.7050 - val_loss: 0.8207 - val_accuracy: 0.6970\n",
            "Epoch 32/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7968 - accuracy: 0.7035 - val_loss: 0.8195 - val_accuracy: 0.6974\n",
            "Epoch 33/300\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.7952 - accuracy: 0.7052 - val_loss: 0.8202 - val_accuracy: 0.6982\n",
            "Epoch 34/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7950 - accuracy: 0.7053 - val_loss: 0.8201 - val_accuracy: 0.6979\n",
            "Epoch 35/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7952 - accuracy: 0.7036 - val_loss: 0.8206 - val_accuracy: 0.6991\n",
            "Epoch 36/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7960 - accuracy: 0.7040 - val_loss: 0.8210 - val_accuracy: 0.6959\n",
            "Epoch 37/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7956 - accuracy: 0.7036 - val_loss: 0.8202 - val_accuracy: 0.6968\n",
            "Epoch 38/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7954 - accuracy: 0.7039 - val_loss: 0.8186 - val_accuracy: 0.6986\n",
            "Epoch 39/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7948 - accuracy: 0.7038 - val_loss: 0.8198 - val_accuracy: 0.6975\n",
            "Epoch 40/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7949 - accuracy: 0.7044 - val_loss: 0.8198 - val_accuracy: 0.6980\n",
            "Epoch 41/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7941 - accuracy: 0.7047 - val_loss: 0.8195 - val_accuracy: 0.6971\n",
            "Epoch 42/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7954 - accuracy: 0.7037 - val_loss: 0.8207 - val_accuracy: 0.6965\n",
            "Epoch 43/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7954 - accuracy: 0.7043 - val_loss: 0.8195 - val_accuracy: 0.6973\n",
            "Epoch 44/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7037 - val_loss: 0.8196 - val_accuracy: 0.6975\n",
            "Epoch 45/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7955 - accuracy: 0.7042 - val_loss: 0.8186 - val_accuracy: 0.6986\n",
            "Epoch 46/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7946 - accuracy: 0.7042 - val_loss: 0.8211 - val_accuracy: 0.6979\n",
            "Epoch 47/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7952 - accuracy: 0.7035 - val_loss: 0.8205 - val_accuracy: 0.6979\n",
            "Epoch 48/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7949 - accuracy: 0.7037 - val_loss: 0.8193 - val_accuracy: 0.6975\n",
            "Epoch 49/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7947 - accuracy: 0.7054 - val_loss: 0.8206 - val_accuracy: 0.6956\n",
            "Epoch 50/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7945 - accuracy: 0.7050 - val_loss: 0.8197 - val_accuracy: 0.6971\n",
            "Epoch 51/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7955 - accuracy: 0.7045 - val_loss: 0.8206 - val_accuracy: 0.6974\n",
            "Epoch 52/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7950 - accuracy: 0.7046 - val_loss: 0.8204 - val_accuracy: 0.6980\n",
            "Epoch 53/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7957 - accuracy: 0.7026 - val_loss: 0.8201 - val_accuracy: 0.6979\n",
            "Epoch 54/300\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.7959 - accuracy: 0.7036 - val_loss: 0.8195 - val_accuracy: 0.6979\n",
            "Epoch 55/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7950 - accuracy: 0.7042 - val_loss: 0.8205 - val_accuracy: 0.6975\n",
            "Epoch 56/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7038 - val_loss: 0.8201 - val_accuracy: 0.6971\n",
            "Epoch 57/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7952 - accuracy: 0.7046 - val_loss: 0.8205 - val_accuracy: 0.6959\n",
            "Epoch 58/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7958 - accuracy: 0.7050 - val_loss: 0.8201 - val_accuracy: 0.6975\n",
            "Epoch 59/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7946 - accuracy: 0.7043 - val_loss: 0.8204 - val_accuracy: 0.6986\n",
            "Epoch 60/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7950 - accuracy: 0.7044 - val_loss: 0.8202 - val_accuracy: 0.6973\n",
            "Epoch 61/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7955 - accuracy: 0.7041 - val_loss: 0.8208 - val_accuracy: 0.6975\n",
            "Epoch 62/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7956 - accuracy: 0.7051 - val_loss: 0.8199 - val_accuracy: 0.6973\n",
            "Epoch 63/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7955 - accuracy: 0.7044 - val_loss: 0.8194 - val_accuracy: 0.6981\n",
            "Epoch 64/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7946 - accuracy: 0.7041 - val_loss: 0.8196 - val_accuracy: 0.6975\n",
            "Epoch 65/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7958 - accuracy: 0.7041 - val_loss: 0.8191 - val_accuracy: 0.6969\n",
            "Epoch 66/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7945 - accuracy: 0.7049 - val_loss: 0.8201 - val_accuracy: 0.6967\n",
            "Epoch 67/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7954 - accuracy: 0.7043 - val_loss: 0.8195 - val_accuracy: 0.6977\n",
            "Epoch 68/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7958 - accuracy: 0.7033 - val_loss: 0.8209 - val_accuracy: 0.6992\n",
            "Epoch 69/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7941 - accuracy: 0.7049 - val_loss: 0.8209 - val_accuracy: 0.6968\n",
            "Epoch 70/300\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.7950 - accuracy: 0.7036 - val_loss: 0.8198 - val_accuracy: 0.6982\n",
            "Epoch 71/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7955 - accuracy: 0.7036 - val_loss: 0.8203 - val_accuracy: 0.6973\n",
            "Epoch 72/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7955 - accuracy: 0.7042 - val_loss: 0.8208 - val_accuracy: 0.6989\n",
            "Epoch 73/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7956 - accuracy: 0.7035 - val_loss: 0.8200 - val_accuracy: 0.6969\n",
            "Epoch 74/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7037 - val_loss: 0.8196 - val_accuracy: 0.6984\n",
            "Epoch 75/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7953 - accuracy: 0.7044 - val_loss: 0.8200 - val_accuracy: 0.6978\n",
            "Epoch 76/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7943 - accuracy: 0.7040 - val_loss: 0.8206 - val_accuracy: 0.6987\n",
            "Epoch 77/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7962 - accuracy: 0.7035 - val_loss: 0.8185 - val_accuracy: 0.6980\n",
            "Epoch 78/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7955 - accuracy: 0.7039 - val_loss: 0.8204 - val_accuracy: 0.6975\n",
            "Epoch 79/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7953 - accuracy: 0.7046 - val_loss: 0.8197 - val_accuracy: 0.6984\n",
            "Epoch 80/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7957 - accuracy: 0.7038 - val_loss: 0.8197 - val_accuracy: 0.6962\n",
            "Epoch 81/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7946 - accuracy: 0.7036 - val_loss: 0.8207 - val_accuracy: 0.6975\n",
            "Epoch 82/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7961 - accuracy: 0.7045 - val_loss: 0.8190 - val_accuracy: 0.6967\n",
            "Epoch 83/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7944 - accuracy: 0.7045 - val_loss: 0.8213 - val_accuracy: 0.6958\n",
            "Epoch 84/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7949 - accuracy: 0.7040 - val_loss: 0.8192 - val_accuracy: 0.6986\n",
            "Epoch 85/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7948 - accuracy: 0.7052 - val_loss: 0.8198 - val_accuracy: 0.6976\n",
            "Epoch 86/300\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.7949 - accuracy: 0.7049 - val_loss: 0.8202 - val_accuracy: 0.6975\n",
            "Epoch 87/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7950 - accuracy: 0.7053 - val_loss: 0.8207 - val_accuracy: 0.6964\n",
            "Epoch 88/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7947 - accuracy: 0.7045 - val_loss: 0.8194 - val_accuracy: 0.6986\n",
            "Epoch 89/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7954 - accuracy: 0.7045 - val_loss: 0.8193 - val_accuracy: 0.6994\n",
            "Epoch 90/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7946 - accuracy: 0.7045 - val_loss: 0.8209 - val_accuracy: 0.6976\n",
            "Epoch 91/300\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.7966 - accuracy: 0.7040 - val_loss: 0.8196 - val_accuracy: 0.6974\n",
            "Epoch 92/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7942 - accuracy: 0.7041 - val_loss: 0.8200 - val_accuracy: 0.6964\n",
            "Epoch 93/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7042 - val_loss: 0.8195 - val_accuracy: 0.6981\n",
            "Epoch 94/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7945 - accuracy: 0.7054 - val_loss: 0.8204 - val_accuracy: 0.6974\n",
            "Epoch 95/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7949 - accuracy: 0.7041 - val_loss: 0.8195 - val_accuracy: 0.6973\n",
            "Epoch 96/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7042 - val_loss: 0.8198 - val_accuracy: 0.6973\n",
            "Epoch 97/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7953 - accuracy: 0.7043 - val_loss: 0.8198 - val_accuracy: 0.6983\n",
            "Epoch 98/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7944 - accuracy: 0.7048 - val_loss: 0.8196 - val_accuracy: 0.6975\n",
            "Epoch 99/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7948 - accuracy: 0.7039 - val_loss: 0.8204 - val_accuracy: 0.6986\n",
            "Epoch 100/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7046 - val_loss: 0.8195 - val_accuracy: 0.6973\n",
            "Epoch 101/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7947 - accuracy: 0.7041 - val_loss: 0.8196 - val_accuracy: 0.6976\n",
            "Epoch 102/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7041 - val_loss: 0.8200 - val_accuracy: 0.6969\n",
            "Epoch 103/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7953 - accuracy: 0.7038 - val_loss: 0.8196 - val_accuracy: 0.6975\n",
            "Epoch 104/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7949 - accuracy: 0.7038 - val_loss: 0.8207 - val_accuracy: 0.6984\n",
            "Epoch 105/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7051 - val_loss: 0.8209 - val_accuracy: 0.6964\n",
            "Epoch 106/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7945 - accuracy: 0.7044 - val_loss: 0.8198 - val_accuracy: 0.6983\n",
            "Epoch 107/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7952 - accuracy: 0.7034 - val_loss: 0.8192 - val_accuracy: 0.6983\n",
            "Epoch 108/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7956 - accuracy: 0.7038 - val_loss: 0.8202 - val_accuracy: 0.6984\n",
            "Epoch 109/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7946 - accuracy: 0.7055 - val_loss: 0.8203 - val_accuracy: 0.6984\n",
            "Epoch 110/300\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.7949 - accuracy: 0.7044 - val_loss: 0.8196 - val_accuracy: 0.6970\n",
            "Epoch 111/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7953 - accuracy: 0.7036 - val_loss: 0.8211 - val_accuracy: 0.6977\n",
            "Epoch 112/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7955 - accuracy: 0.7030 - val_loss: 0.8196 - val_accuracy: 0.6975\n",
            "Epoch 113/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7953 - accuracy: 0.7042 - val_loss: 0.8208 - val_accuracy: 0.6984\n",
            "Epoch 114/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7954 - accuracy: 0.7042 - val_loss: 0.8189 - val_accuracy: 0.6984\n",
            "Epoch 115/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7944 - accuracy: 0.7049 - val_loss: 0.8198 - val_accuracy: 0.6989\n",
            "Epoch 116/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7943 - accuracy: 0.7046 - val_loss: 0.8192 - val_accuracy: 0.6977\n",
            "Epoch 117/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7946 - accuracy: 0.7041 - val_loss: 0.8207 - val_accuracy: 0.6978\n",
            "Epoch 118/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7950 - accuracy: 0.7044 - val_loss: 0.8189 - val_accuracy: 0.6983\n",
            "Epoch 119/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7946 - accuracy: 0.7045 - val_loss: 0.8200 - val_accuracy: 0.6964\n",
            "Epoch 120/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7050 - val_loss: 0.8192 - val_accuracy: 0.6974\n",
            "Epoch 121/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7955 - accuracy: 0.7043 - val_loss: 0.8209 - val_accuracy: 0.6963\n",
            "Epoch 122/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7947 - accuracy: 0.7050 - val_loss: 0.8202 - val_accuracy: 0.6978\n",
            "Epoch 123/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7945 - accuracy: 0.7039 - val_loss: 0.8210 - val_accuracy: 0.6977\n",
            "Epoch 124/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7945 - accuracy: 0.7050 - val_loss: 0.8215 - val_accuracy: 0.6965\n",
            "Epoch 125/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7943 - accuracy: 0.7052 - val_loss: 0.8198 - val_accuracy: 0.6969\n",
            "Epoch 126/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7933 - accuracy: 0.7049 - val_loss: 0.8218 - val_accuracy: 0.6975\n",
            "Epoch 127/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7941 - accuracy: 0.7047 - val_loss: 0.8208 - val_accuracy: 0.6986\n",
            "Epoch 128/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7950 - accuracy: 0.7040 - val_loss: 0.8196 - val_accuracy: 0.6982\n",
            "Epoch 129/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7039 - val_loss: 0.8209 - val_accuracy: 0.6987\n",
            "Epoch 130/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7037 - val_loss: 0.8203 - val_accuracy: 0.6982\n",
            "Epoch 131/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7947 - accuracy: 0.7044 - val_loss: 0.8204 - val_accuracy: 0.6985\n",
            "Epoch 132/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7943 - accuracy: 0.7042 - val_loss: 0.8198 - val_accuracy: 0.6979\n",
            "Epoch 133/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7945 - accuracy: 0.7040 - val_loss: 0.8210 - val_accuracy: 0.6965\n",
            "Epoch 134/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7959 - accuracy: 0.7036 - val_loss: 0.8198 - val_accuracy: 0.6976\n",
            "Epoch 135/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7949 - accuracy: 0.7047 - val_loss: 0.8197 - val_accuracy: 0.6980\n",
            "Epoch 136/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7946 - accuracy: 0.7033 - val_loss: 0.8201 - val_accuracy: 0.6969\n",
            "Epoch 137/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7953 - accuracy: 0.7040 - val_loss: 0.8199 - val_accuracy: 0.6983\n",
            "Epoch 138/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7953 - accuracy: 0.7049 - val_loss: 0.8202 - val_accuracy: 0.6977\n",
            "Epoch 139/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7953 - accuracy: 0.7041 - val_loss: 0.8209 - val_accuracy: 0.6981\n",
            "Epoch 140/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7948 - accuracy: 0.7039 - val_loss: 0.8208 - val_accuracy: 0.6967\n",
            "Epoch 141/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7031 - val_loss: 0.8200 - val_accuracy: 0.6982\n",
            "Epoch 142/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7949 - accuracy: 0.7029 - val_loss: 0.8198 - val_accuracy: 0.6965\n",
            "Epoch 143/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7931 - accuracy: 0.7047 - val_loss: 0.8207 - val_accuracy: 0.6973\n",
            "Epoch 144/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7946 - accuracy: 0.7042 - val_loss: 0.8198 - val_accuracy: 0.6974\n",
            "Epoch 145/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7939 - accuracy: 0.7039 - val_loss: 0.8207 - val_accuracy: 0.6960\n",
            "Epoch 146/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7955 - accuracy: 0.7027 - val_loss: 0.8201 - val_accuracy: 0.6978\n",
            "Epoch 147/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7956 - accuracy: 0.7040 - val_loss: 0.8208 - val_accuracy: 0.6977\n",
            "Epoch 148/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7950 - accuracy: 0.7047 - val_loss: 0.8204 - val_accuracy: 0.6967\n",
            "Epoch 149/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7949 - accuracy: 0.7044 - val_loss: 0.8208 - val_accuracy: 0.6980\n",
            "Epoch 150/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7953 - accuracy: 0.7032 - val_loss: 0.8206 - val_accuracy: 0.6977\n",
            "Epoch 151/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7961 - accuracy: 0.7028 - val_loss: 0.8200 - val_accuracy: 0.6980\n",
            "Epoch 152/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7947 - accuracy: 0.7043 - val_loss: 0.8213 - val_accuracy: 0.6972\n",
            "Epoch 153/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7954 - accuracy: 0.7043 - val_loss: 0.8198 - val_accuracy: 0.6973\n",
            "Epoch 154/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7956 - accuracy: 0.7034 - val_loss: 0.8213 - val_accuracy: 0.6989\n",
            "Epoch 155/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7949 - accuracy: 0.7039 - val_loss: 0.8205 - val_accuracy: 0.6972\n",
            "Epoch 156/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7953 - accuracy: 0.7036 - val_loss: 0.8203 - val_accuracy: 0.6979\n",
            "Epoch 157/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7944 - accuracy: 0.7038 - val_loss: 0.8205 - val_accuracy: 0.6970\n",
            "Epoch 158/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7946 - accuracy: 0.7043 - val_loss: 0.8198 - val_accuracy: 0.6993\n",
            "Epoch 159/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7942 - accuracy: 0.7031 - val_loss: 0.8217 - val_accuracy: 0.6946\n",
            "Epoch 160/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7952 - accuracy: 0.7026 - val_loss: 0.8205 - val_accuracy: 0.6971\n",
            "Epoch 161/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7942 - accuracy: 0.7047 - val_loss: 0.8213 - val_accuracy: 0.6967\n",
            "Epoch 162/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7955 - accuracy: 0.7040 - val_loss: 0.8201 - val_accuracy: 0.6971\n",
            "Epoch 163/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7948 - accuracy: 0.7039 - val_loss: 0.8201 - val_accuracy: 0.6975\n",
            "Epoch 164/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7040 - val_loss: 0.8193 - val_accuracy: 0.6984\n",
            "Epoch 165/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7950 - accuracy: 0.7043 - val_loss: 0.8201 - val_accuracy: 0.6986\n",
            "Epoch 166/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7937 - accuracy: 0.7052 - val_loss: 0.8203 - val_accuracy: 0.6978\n",
            "Epoch 167/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7954 - accuracy: 0.7045 - val_loss: 0.8204 - val_accuracy: 0.6972\n",
            "Epoch 168/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7039 - val_loss: 0.8197 - val_accuracy: 0.6994\n",
            "Epoch 169/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7946 - accuracy: 0.7044 - val_loss: 0.8204 - val_accuracy: 0.6983\n",
            "Epoch 170/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7958 - accuracy: 0.7042 - val_loss: 0.8200 - val_accuracy: 0.6983\n",
            "Epoch 171/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7948 - accuracy: 0.7048 - val_loss: 0.8214 - val_accuracy: 0.6968\n",
            "Epoch 172/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7947 - accuracy: 0.7046 - val_loss: 0.8199 - val_accuracy: 0.6975\n",
            "Epoch 173/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7952 - accuracy: 0.7036 - val_loss: 0.8200 - val_accuracy: 0.6977\n",
            "Epoch 174/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7944 - accuracy: 0.7051 - val_loss: 0.8199 - val_accuracy: 0.6974\n",
            "Epoch 175/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7950 - accuracy: 0.7042 - val_loss: 0.8217 - val_accuracy: 0.6969\n",
            "Epoch 176/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7962 - accuracy: 0.7049 - val_loss: 0.8199 - val_accuracy: 0.6978\n",
            "Epoch 177/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7950 - accuracy: 0.7048 - val_loss: 0.8210 - val_accuracy: 0.6987\n",
            "Epoch 178/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7950 - accuracy: 0.7042 - val_loss: 0.8205 - val_accuracy: 0.6980\n",
            "Epoch 179/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7947 - accuracy: 0.7045 - val_loss: 0.8213 - val_accuracy: 0.6982\n",
            "Epoch 180/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7949 - accuracy: 0.7037 - val_loss: 0.8200 - val_accuracy: 0.6979\n",
            "Epoch 181/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7954 - accuracy: 0.7037 - val_loss: 0.8204 - val_accuracy: 0.6963\n",
            "Epoch 182/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7956 - accuracy: 0.7039 - val_loss: 0.8201 - val_accuracy: 0.6988\n",
            "Epoch 183/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7032 - val_loss: 0.8212 - val_accuracy: 0.6978\n",
            "Epoch 184/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7953 - accuracy: 0.7043 - val_loss: 0.8208 - val_accuracy: 0.6972\n",
            "Epoch 185/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7955 - accuracy: 0.7038 - val_loss: 0.8204 - val_accuracy: 0.6961\n",
            "Epoch 186/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7953 - accuracy: 0.7040 - val_loss: 0.8200 - val_accuracy: 0.6978\n",
            "Epoch 187/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7954 - accuracy: 0.7036 - val_loss: 0.8196 - val_accuracy: 0.6976\n",
            "Epoch 188/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7942 - accuracy: 0.7046 - val_loss: 0.8203 - val_accuracy: 0.6976\n",
            "Epoch 189/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7941 - accuracy: 0.7045 - val_loss: 0.8199 - val_accuracy: 0.6993\n",
            "Epoch 190/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7947 - accuracy: 0.7036 - val_loss: 0.8205 - val_accuracy: 0.6977\n",
            "Epoch 191/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7947 - accuracy: 0.7043 - val_loss: 0.8209 - val_accuracy: 0.6979\n",
            "Epoch 192/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7938 - accuracy: 0.7043 - val_loss: 0.8197 - val_accuracy: 0.6980\n",
            "Epoch 193/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7938 - accuracy: 0.7045 - val_loss: 0.8192 - val_accuracy: 0.6979\n",
            "Epoch 194/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7951 - accuracy: 0.7044 - val_loss: 0.8200 - val_accuracy: 0.6973\n",
            "Epoch 195/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7957 - accuracy: 0.7039 - val_loss: 0.8207 - val_accuracy: 0.6975\n",
            "Epoch 196/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7948 - accuracy: 0.7039 - val_loss: 0.8204 - val_accuracy: 0.6984\n",
            "Epoch 197/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7953 - accuracy: 0.7034 - val_loss: 0.8202 - val_accuracy: 0.6984\n",
            "Epoch 198/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7940 - accuracy: 0.7034 - val_loss: 0.8198 - val_accuracy: 0.6972\n",
            "Epoch 199/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7945 - accuracy: 0.7058 - val_loss: 0.8195 - val_accuracy: 0.6975\n",
            "Epoch 200/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7944 - accuracy: 0.7034 - val_loss: 0.8205 - val_accuracy: 0.6982\n",
            "Epoch 201/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7947 - accuracy: 0.7055 - val_loss: 0.8199 - val_accuracy: 0.6974\n",
            "Epoch 202/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7946 - accuracy: 0.7045 - val_loss: 0.8205 - val_accuracy: 0.6961\n",
            "Epoch 203/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7944 - accuracy: 0.7053 - val_loss: 0.8209 - val_accuracy: 0.6977\n",
            "Epoch 204/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7948 - accuracy: 0.7042 - val_loss: 0.8201 - val_accuracy: 0.6965\n",
            "Epoch 205/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7946 - accuracy: 0.7045 - val_loss: 0.8199 - val_accuracy: 0.6973\n",
            "Epoch 206/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7037 - val_loss: 0.8211 - val_accuracy: 0.6970\n",
            "Epoch 207/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7944 - accuracy: 0.7055 - val_loss: 0.8193 - val_accuracy: 0.6973\n",
            "Epoch 208/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7946 - accuracy: 0.7042 - val_loss: 0.8202 - val_accuracy: 0.6973\n",
            "Epoch 209/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7957 - accuracy: 0.7033 - val_loss: 0.8198 - val_accuracy: 0.6975\n",
            "Epoch 210/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7044 - val_loss: 0.8196 - val_accuracy: 0.6985\n",
            "Epoch 211/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7940 - accuracy: 0.7042 - val_loss: 0.8194 - val_accuracy: 0.6982\n",
            "Epoch 212/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7949 - accuracy: 0.7045 - val_loss: 0.8207 - val_accuracy: 0.6972\n",
            "Epoch 213/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7948 - accuracy: 0.7039 - val_loss: 0.8196 - val_accuracy: 0.6990\n",
            "Epoch 214/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7945 - accuracy: 0.7050 - val_loss: 0.8193 - val_accuracy: 0.6978\n",
            "Epoch 215/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7946 - accuracy: 0.7040 - val_loss: 0.8199 - val_accuracy: 0.6963\n",
            "Epoch 216/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7940 - accuracy: 0.7046 - val_loss: 0.8195 - val_accuracy: 0.6975\n",
            "Epoch 217/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7954 - accuracy: 0.7042 - val_loss: 0.8204 - val_accuracy: 0.6959\n",
            "Epoch 218/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7946 - accuracy: 0.7040 - val_loss: 0.8198 - val_accuracy: 0.6968\n",
            "Epoch 219/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7939 - accuracy: 0.7047 - val_loss: 0.8208 - val_accuracy: 0.6961\n",
            "Epoch 220/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7947 - accuracy: 0.7048 - val_loss: 0.8200 - val_accuracy: 0.6984\n",
            "Epoch 221/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7950 - accuracy: 0.7032 - val_loss: 0.8209 - val_accuracy: 0.6972\n",
            "Epoch 222/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7945 - accuracy: 0.7048 - val_loss: 0.8204 - val_accuracy: 0.6989\n",
            "Epoch 223/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7954 - accuracy: 0.7028 - val_loss: 0.8198 - val_accuracy: 0.6978\n",
            "Epoch 224/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7950 - accuracy: 0.7036 - val_loss: 0.8209 - val_accuracy: 0.6973\n",
            "Epoch 225/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7949 - accuracy: 0.7040 - val_loss: 0.8206 - val_accuracy: 0.6980\n",
            "Epoch 226/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7949 - accuracy: 0.7049 - val_loss: 0.8193 - val_accuracy: 0.6982\n",
            "Epoch 227/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7945 - accuracy: 0.7036 - val_loss: 0.8203 - val_accuracy: 0.6992\n",
            "Epoch 228/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7941 - accuracy: 0.7038 - val_loss: 0.8207 - val_accuracy: 0.6980\n",
            "Epoch 229/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7947 - accuracy: 0.7027 - val_loss: 0.8200 - val_accuracy: 0.6974\n",
            "Epoch 230/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7951 - accuracy: 0.7044 - val_loss: 0.8198 - val_accuracy: 0.6983\n",
            "Epoch 231/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7960 - accuracy: 0.7044 - val_loss: 0.8198 - val_accuracy: 0.6967\n",
            "Epoch 232/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7939 - accuracy: 0.7041 - val_loss: 0.8200 - val_accuracy: 0.6958\n",
            "Epoch 233/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7941 - accuracy: 0.7045 - val_loss: 0.8196 - val_accuracy: 0.6962\n",
            "Epoch 234/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7944 - accuracy: 0.7039 - val_loss: 0.8209 - val_accuracy: 0.6960\n",
            "Epoch 235/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7959 - accuracy: 0.7034 - val_loss: 0.8206 - val_accuracy: 0.6964\n",
            "Epoch 236/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7939 - accuracy: 0.7054 - val_loss: 0.8204 - val_accuracy: 0.6978\n",
            "Epoch 237/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7945 - accuracy: 0.7040 - val_loss: 0.8199 - val_accuracy: 0.6983\n",
            "Epoch 238/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7951 - accuracy: 0.7036 - val_loss: 0.8192 - val_accuracy: 0.6997\n",
            "Epoch 239/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7932 - accuracy: 0.7047 - val_loss: 0.8216 - val_accuracy: 0.6955\n",
            "Epoch 240/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7029 - val_loss: 0.8198 - val_accuracy: 0.6986\n",
            "Epoch 241/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7936 - accuracy: 0.7039 - val_loss: 0.8197 - val_accuracy: 0.6975\n",
            "Epoch 242/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7941 - accuracy: 0.7040 - val_loss: 0.8210 - val_accuracy: 0.6982\n",
            "Epoch 243/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7045 - val_loss: 0.8199 - val_accuracy: 0.6977\n",
            "Epoch 244/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7945 - accuracy: 0.7044 - val_loss: 0.8197 - val_accuracy: 0.6979\n",
            "Epoch 245/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7949 - accuracy: 0.7050 - val_loss: 0.8206 - val_accuracy: 0.6971\n",
            "Epoch 246/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7942 - accuracy: 0.7048 - val_loss: 0.8202 - val_accuracy: 0.6996\n",
            "Epoch 247/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7938 - accuracy: 0.7048 - val_loss: 0.8208 - val_accuracy: 0.6971\n",
            "Epoch 248/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7945 - accuracy: 0.7044 - val_loss: 0.8194 - val_accuracy: 0.6994\n",
            "Epoch 249/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7953 - accuracy: 0.7036 - val_loss: 0.8198 - val_accuracy: 0.6983\n",
            "Epoch 250/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7944 - accuracy: 0.7058 - val_loss: 0.8198 - val_accuracy: 0.6964\n",
            "Epoch 251/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7936 - accuracy: 0.7059 - val_loss: 0.8215 - val_accuracy: 0.6965\n",
            "Epoch 252/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7946 - accuracy: 0.7050 - val_loss: 0.8204 - val_accuracy: 0.6980\n",
            "Epoch 253/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7947 - accuracy: 0.7032 - val_loss: 0.8211 - val_accuracy: 0.6959\n",
            "Epoch 254/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7938 - accuracy: 0.7030 - val_loss: 0.8197 - val_accuracy: 0.6960\n",
            "Epoch 255/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7941 - accuracy: 0.7052 - val_loss: 0.8200 - val_accuracy: 0.6968\n",
            "Epoch 256/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7942 - accuracy: 0.7050 - val_loss: 0.8218 - val_accuracy: 0.6969\n",
            "Epoch 257/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7949 - accuracy: 0.7039 - val_loss: 0.8199 - val_accuracy: 0.6968\n",
            "Epoch 258/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7938 - accuracy: 0.7039 - val_loss: 0.8215 - val_accuracy: 0.6968\n",
            "Epoch 259/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7955 - accuracy: 0.7045 - val_loss: 0.8204 - val_accuracy: 0.6969\n",
            "Epoch 260/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7941 - accuracy: 0.7036 - val_loss: 0.8213 - val_accuracy: 0.6975\n",
            "Epoch 261/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7945 - accuracy: 0.7046 - val_loss: 0.8216 - val_accuracy: 0.6967\n",
            "Epoch 262/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7938 - accuracy: 0.7044 - val_loss: 0.8221 - val_accuracy: 0.6969\n",
            "Epoch 263/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7948 - accuracy: 0.7031 - val_loss: 0.8195 - val_accuracy: 0.6974\n",
            "Epoch 264/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7936 - accuracy: 0.7049 - val_loss: 0.8206 - val_accuracy: 0.6985\n",
            "Epoch 265/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7944 - accuracy: 0.7045 - val_loss: 0.8190 - val_accuracy: 0.6986\n",
            "Epoch 266/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7944 - accuracy: 0.7039 - val_loss: 0.8203 - val_accuracy: 0.6996\n",
            "Epoch 267/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7935 - accuracy: 0.7049 - val_loss: 0.8196 - val_accuracy: 0.6980\n",
            "Epoch 268/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7946 - accuracy: 0.7044 - val_loss: 0.8204 - val_accuracy: 0.6973\n",
            "Epoch 269/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7952 - accuracy: 0.7031 - val_loss: 0.8206 - val_accuracy: 0.6967\n",
            "Epoch 270/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7953 - accuracy: 0.7029 - val_loss: 0.8199 - val_accuracy: 0.6980\n",
            "Epoch 271/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7958 - accuracy: 0.7045 - val_loss: 0.8202 - val_accuracy: 0.6978\n",
            "Epoch 272/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7941 - accuracy: 0.7042 - val_loss: 0.8200 - val_accuracy: 0.6965\n",
            "Epoch 273/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7050 - val_loss: 0.8192 - val_accuracy: 0.6972\n",
            "Epoch 274/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7945 - accuracy: 0.7048 - val_loss: 0.8191 - val_accuracy: 0.6987\n",
            "Epoch 275/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7949 - accuracy: 0.7045 - val_loss: 0.8198 - val_accuracy: 0.6987\n",
            "Epoch 276/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7938 - accuracy: 0.7046 - val_loss: 0.8205 - val_accuracy: 0.6948\n",
            "Epoch 277/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7944 - accuracy: 0.7041 - val_loss: 0.8192 - val_accuracy: 0.6960\n",
            "Epoch 278/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7941 - accuracy: 0.7038 - val_loss: 0.8193 - val_accuracy: 0.6984\n",
            "Epoch 279/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7946 - accuracy: 0.7044 - val_loss: 0.8215 - val_accuracy: 0.6985\n",
            "Epoch 280/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7946 - accuracy: 0.7040 - val_loss: 0.8207 - val_accuracy: 0.6987\n",
            "Epoch 281/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7948 - accuracy: 0.7031 - val_loss: 0.8201 - val_accuracy: 0.6987\n",
            "Epoch 282/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7934 - accuracy: 0.7038 - val_loss: 0.8210 - val_accuracy: 0.6978\n",
            "Epoch 283/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7939 - accuracy: 0.7044 - val_loss: 0.8202 - val_accuracy: 0.6967\n",
            "Epoch 284/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7935 - accuracy: 0.7049 - val_loss: 0.8203 - val_accuracy: 0.6973\n",
            "Epoch 285/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7944 - accuracy: 0.7050 - val_loss: 0.8205 - val_accuracy: 0.6960\n",
            "Epoch 286/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7936 - accuracy: 0.7036 - val_loss: 0.8198 - val_accuracy: 0.6981\n",
            "Epoch 287/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7948 - accuracy: 0.7036 - val_loss: 0.8217 - val_accuracy: 0.6993\n",
            "Epoch 288/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7946 - accuracy: 0.7038 - val_loss: 0.8200 - val_accuracy: 0.6983\n",
            "Epoch 289/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7939 - accuracy: 0.7040 - val_loss: 0.8202 - val_accuracy: 0.6965\n",
            "Epoch 290/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7947 - accuracy: 0.7039 - val_loss: 0.8216 - val_accuracy: 0.6965\n",
            "Epoch 291/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7953 - accuracy: 0.7046 - val_loss: 0.8204 - val_accuracy: 0.6973\n",
            "Epoch 292/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7951 - accuracy: 0.7032 - val_loss: 0.8209 - val_accuracy: 0.6962\n",
            "Epoch 293/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7946 - accuracy: 0.7044 - val_loss: 0.8203 - val_accuracy: 0.6976\n",
            "Epoch 294/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7945 - accuracy: 0.7036 - val_loss: 0.8203 - val_accuracy: 0.6992\n",
            "Epoch 295/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7025 - val_loss: 0.8199 - val_accuracy: 0.6969\n",
            "Epoch 296/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7943 - accuracy: 0.7035 - val_loss: 0.8202 - val_accuracy: 0.6974\n",
            "Epoch 297/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7944 - accuracy: 0.7035 - val_loss: 0.8199 - val_accuracy: 0.6974\n",
            "Epoch 298/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7948 - accuracy: 0.7053 - val_loss: 0.8218 - val_accuracy: 0.6980\n",
            "Epoch 299/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7949 - accuracy: 0.7045 - val_loss: 0.8195 - val_accuracy: 0.6993\n",
            "Epoch 300/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7950 - accuracy: 0.7041 - val_loss: 0.8214 - val_accuracy: 0.6969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT2flZz94P7x",
        "outputId": "17a5051c-2ecb-44cb-98fc-b38926c03440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit( np.array(x_train_pad), \n",
        "                    np.array(y_train),\n",
        "                    batch_size=2048, \n",
        "                    epochs=200, \n",
        "                    validation_data= (np.array(x_val_pad),\n",
        "                        np.array(y_val)),\n",
        "                    verbose=1)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2769 - accuracy: 0.7040 - val_loss: 0.2824 - val_accuracy: 0.6956\n",
            "Epoch 2/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2767 - accuracy: 0.7035 - val_loss: 0.2839 - val_accuracy: 0.6939\n",
            "Epoch 3/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2771 - accuracy: 0.7038 - val_loss: 0.2836 - val_accuracy: 0.6971\n",
            "Epoch 4/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2769 - accuracy: 0.7041 - val_loss: 0.2823 - val_accuracy: 0.6988\n",
            "Epoch 5/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2771 - accuracy: 0.7040 - val_loss: 0.2819 - val_accuracy: 0.6992\n",
            "Epoch 6/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2770 - accuracy: 0.7022 - val_loss: 0.2833 - val_accuracy: 0.6968\n",
            "Epoch 7/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2770 - accuracy: 0.7027 - val_loss: 0.2836 - val_accuracy: 0.6978\n",
            "Epoch 8/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2769 - accuracy: 0.7030 - val_loss: 0.2822 - val_accuracy: 0.6959\n",
            "Epoch 9/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2769 - accuracy: 0.7030 - val_loss: 0.2826 - val_accuracy: 0.6945\n",
            "Epoch 10/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2770 - accuracy: 0.7031 - val_loss: 0.2862 - val_accuracy: 0.6894\n",
            "Epoch 11/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.2768 - accuracy: 0.7038 - val_loss: 0.2834 - val_accuracy: 0.6948\n",
            "Epoch 12/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2767 - accuracy: 0.7038 - val_loss: 0.2821 - val_accuracy: 0.6956\n",
            "Epoch 13/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2771 - accuracy: 0.7028 - val_loss: 0.2815 - val_accuracy: 0.6973\n",
            "Epoch 14/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2771 - accuracy: 0.7031 - val_loss: 0.2832 - val_accuracy: 0.6935\n",
            "Epoch 15/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2768 - accuracy: 0.7039 - val_loss: 0.2849 - val_accuracy: 0.6929\n",
            "Epoch 16/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.2767 - accuracy: 0.7038 - val_loss: 0.2831 - val_accuracy: 0.6975\n",
            "Epoch 17/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2767 - accuracy: 0.7037 - val_loss: 0.2818 - val_accuracy: 0.6977\n",
            "Epoch 18/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2770 - accuracy: 0.7031 - val_loss: 0.2833 - val_accuracy: 0.6957\n",
            "Epoch 19/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2764 - accuracy: 0.7044 - val_loss: 0.2840 - val_accuracy: 0.6937\n",
            "Epoch 20/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2768 - accuracy: 0.7028 - val_loss: 0.2854 - val_accuracy: 0.6964\n",
            "Epoch 21/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2768 - accuracy: 0.7035 - val_loss: 0.2822 - val_accuracy: 0.6977\n",
            "Epoch 22/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2766 - accuracy: 0.7045 - val_loss: 0.2812 - val_accuracy: 0.6996\n",
            "Epoch 23/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.2765 - accuracy: 0.7049 - val_loss: 0.2857 - val_accuracy: 0.6952\n",
            "Epoch 24/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2768 - accuracy: 0.7044 - val_loss: 0.2832 - val_accuracy: 0.6982\n",
            "Epoch 25/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2765 - accuracy: 0.7045 - val_loss: 0.2813 - val_accuracy: 0.6973\n",
            "Epoch 26/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2764 - accuracy: 0.7042 - val_loss: 0.2864 - val_accuracy: 0.6964\n",
            "Epoch 27/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2767 - accuracy: 0.7034 - val_loss: 0.2823 - val_accuracy: 0.6950\n",
            "Epoch 28/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2768 - accuracy: 0.7031 - val_loss: 0.2825 - val_accuracy: 0.6964\n",
            "Epoch 29/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2765 - accuracy: 0.7050 - val_loss: 0.2840 - val_accuracy: 0.6964\n",
            "Epoch 30/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2766 - accuracy: 0.7042 - val_loss: 0.2823 - val_accuracy: 0.6966\n",
            "Epoch 31/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2764 - accuracy: 0.7054 - val_loss: 0.2820 - val_accuracy: 0.6987\n",
            "Epoch 32/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2769 - accuracy: 0.7041 - val_loss: 0.2822 - val_accuracy: 0.6980\n",
            "Epoch 33/200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2765 - accuracy: 0.7042 - val_loss: 0.2829 - val_accuracy: 0.6975\n",
            "Epoch 34/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2764 - accuracy: 0.7035 - val_loss: 0.2829 - val_accuracy: 0.6943\n",
            "Epoch 35/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2768 - accuracy: 0.7041 - val_loss: 0.2837 - val_accuracy: 0.6956\n",
            "Epoch 36/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2768 - accuracy: 0.7034 - val_loss: 0.2848 - val_accuracy: 0.6924\n",
            "Epoch 37/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2767 - accuracy: 0.7034 - val_loss: 0.2843 - val_accuracy: 0.6937\n",
            "Epoch 38/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2766 - accuracy: 0.7039 - val_loss: 0.2839 - val_accuracy: 0.6988\n",
            "Epoch 39/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2764 - accuracy: 0.7042 - val_loss: 0.2820 - val_accuracy: 0.6974\n",
            "Epoch 40/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2763 - accuracy: 0.7038 - val_loss: 0.2849 - val_accuracy: 0.6953\n",
            "Epoch 41/200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2769 - accuracy: 0.7035 - val_loss: 0.2821 - val_accuracy: 0.6978\n",
            "Epoch 42/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2761 - accuracy: 0.7044 - val_loss: 0.2852 - val_accuracy: 0.6972\n",
            "Epoch 43/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2766 - accuracy: 0.7036 - val_loss: 0.2834 - val_accuracy: 0.6951\n",
            "Epoch 44/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2765 - accuracy: 0.7044 - val_loss: 0.2824 - val_accuracy: 0.6951\n",
            "Epoch 45/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2762 - accuracy: 0.7037 - val_loss: 0.2831 - val_accuracy: 0.6937\n",
            "Epoch 46/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2765 - accuracy: 0.7030 - val_loss: 0.2829 - val_accuracy: 0.6957\n",
            "Epoch 47/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2764 - accuracy: 0.7047 - val_loss: 0.2825 - val_accuracy: 0.6955\n",
            "Epoch 48/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2765 - accuracy: 0.7058 - val_loss: 0.2823 - val_accuracy: 0.6963\n",
            "Epoch 49/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2762 - accuracy: 0.7044 - val_loss: 0.2850 - val_accuracy: 0.6944\n",
            "Epoch 50/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2764 - accuracy: 0.7041 - val_loss: 0.2820 - val_accuracy: 0.6961\n",
            "Epoch 51/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2766 - accuracy: 0.7046 - val_loss: 0.2847 - val_accuracy: 0.6946\n",
            "Epoch 52/200\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.2763 - accuracy: 0.7032 - val_loss: 0.2835 - val_accuracy: 0.6966\n",
            "Epoch 53/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2763 - accuracy: 0.7045 - val_loss: 0.2827 - val_accuracy: 0.6947\n",
            "Epoch 54/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2763 - accuracy: 0.7047 - val_loss: 0.2878 - val_accuracy: 0.6890\n",
            "Epoch 55/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2763 - accuracy: 0.7042 - val_loss: 0.2824 - val_accuracy: 0.6974\n",
            "Epoch 56/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2762 - accuracy: 0.7037 - val_loss: 0.2837 - val_accuracy: 0.6960\n",
            "Epoch 57/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2764 - accuracy: 0.7039 - val_loss: 0.2814 - val_accuracy: 0.6959\n",
            "Epoch 58/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2764 - accuracy: 0.7044 - val_loss: 0.2818 - val_accuracy: 0.6978\n",
            "Epoch 59/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2763 - accuracy: 0.7041 - val_loss: 0.2844 - val_accuracy: 0.6918\n",
            "Epoch 60/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2765 - accuracy: 0.7034 - val_loss: 0.2833 - val_accuracy: 0.6965\n",
            "Epoch 61/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2764 - accuracy: 0.7032 - val_loss: 0.2818 - val_accuracy: 0.6977\n",
            "Epoch 62/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2762 - accuracy: 0.7032 - val_loss: 0.2830 - val_accuracy: 0.6956\n",
            "Epoch 63/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2762 - accuracy: 0.7043 - val_loss: 0.2832 - val_accuracy: 0.6948\n",
            "Epoch 64/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2762 - accuracy: 0.7036 - val_loss: 0.2828 - val_accuracy: 0.6958\n",
            "Epoch 65/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2763 - accuracy: 0.7042 - val_loss: 0.2818 - val_accuracy: 0.6967\n",
            "Epoch 66/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2761 - accuracy: 0.7041 - val_loss: 0.2819 - val_accuracy: 0.6968\n",
            "Epoch 67/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2760 - accuracy: 0.7046 - val_loss: 0.2880 - val_accuracy: 0.6956\n",
            "Epoch 68/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2759 - accuracy: 0.7052 - val_loss: 0.2839 - val_accuracy: 0.6951\n",
            "Epoch 69/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2764 - accuracy: 0.7035 - val_loss: 0.2832 - val_accuracy: 0.6965\n",
            "Epoch 70/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2761 - accuracy: 0.7046 - val_loss: 0.2820 - val_accuracy: 0.6964\n",
            "Epoch 71/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2759 - accuracy: 0.7051 - val_loss: 0.2831 - val_accuracy: 0.6947\n",
            "Epoch 72/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2763 - accuracy: 0.7044 - val_loss: 0.2834 - val_accuracy: 0.6968\n",
            "Epoch 73/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2761 - accuracy: 0.7039 - val_loss: 0.2819 - val_accuracy: 0.6953\n",
            "Epoch 74/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2763 - accuracy: 0.7038 - val_loss: 0.2843 - val_accuracy: 0.6910\n",
            "Epoch 75/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2761 - accuracy: 0.7048 - val_loss: 0.2825 - val_accuracy: 0.6974\n",
            "Epoch 76/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2763 - accuracy: 0.7043 - val_loss: 0.2824 - val_accuracy: 0.6990\n",
            "Epoch 77/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2763 - accuracy: 0.7044 - val_loss: 0.2830 - val_accuracy: 0.6977\n",
            "Epoch 78/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2763 - accuracy: 0.7045 - val_loss: 0.2821 - val_accuracy: 0.6969\n",
            "Epoch 79/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2760 - accuracy: 0.7045 - val_loss: 0.2820 - val_accuracy: 0.6982\n",
            "Epoch 80/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2761 - accuracy: 0.7050 - val_loss: 0.2818 - val_accuracy: 0.6984\n",
            "Epoch 81/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2762 - accuracy: 0.7040 - val_loss: 0.2823 - val_accuracy: 0.6983\n",
            "Epoch 82/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2763 - accuracy: 0.7022 - val_loss: 0.2827 - val_accuracy: 0.6964\n",
            "Epoch 83/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2758 - accuracy: 0.7040 - val_loss: 0.2829 - val_accuracy: 0.6951\n",
            "Epoch 84/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2760 - accuracy: 0.7047 - val_loss: 0.2823 - val_accuracy: 0.6968\n",
            "Epoch 85/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2761 - accuracy: 0.7037 - val_loss: 0.2826 - val_accuracy: 0.6970\n",
            "Epoch 86/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2761 - accuracy: 0.7039 - val_loss: 0.2826 - val_accuracy: 0.6970\n",
            "Epoch 87/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2761 - accuracy: 0.7046 - val_loss: 0.2828 - val_accuracy: 0.6971\n",
            "Epoch 88/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2756 - accuracy: 0.7053 - val_loss: 0.2825 - val_accuracy: 0.6966\n",
            "Epoch 89/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2763 - accuracy: 0.7044 - val_loss: 0.2819 - val_accuracy: 0.6965\n",
            "Epoch 90/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2762 - accuracy: 0.7033 - val_loss: 0.2831 - val_accuracy: 0.6975\n",
            "Epoch 91/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2760 - accuracy: 0.7042 - val_loss: 0.2827 - val_accuracy: 0.6973\n",
            "Epoch 92/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2757 - accuracy: 0.7049 - val_loss: 0.2841 - val_accuracy: 0.6935\n",
            "Epoch 93/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2762 - accuracy: 0.7028 - val_loss: 0.2830 - val_accuracy: 0.6947\n",
            "Epoch 94/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2759 - accuracy: 0.7037 - val_loss: 0.2826 - val_accuracy: 0.6953\n",
            "Epoch 95/200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2759 - accuracy: 0.7039 - val_loss: 0.2828 - val_accuracy: 0.6931\n",
            "Epoch 96/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2759 - accuracy: 0.7036 - val_loss: 0.2826 - val_accuracy: 0.6948\n",
            "Epoch 97/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2760 - accuracy: 0.7044 - val_loss: 0.2817 - val_accuracy: 0.6967\n",
            "Epoch 98/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2757 - accuracy: 0.7042 - val_loss: 0.2828 - val_accuracy: 0.6963\n",
            "Epoch 99/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2762 - accuracy: 0.7050 - val_loss: 0.2829 - val_accuracy: 0.6936\n",
            "Epoch 100/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2759 - accuracy: 0.7056 - val_loss: 0.2826 - val_accuracy: 0.6946\n",
            "Epoch 101/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2760 - accuracy: 0.7039 - val_loss: 0.2829 - val_accuracy: 0.6973\n",
            "Epoch 102/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2761 - accuracy: 0.7044 - val_loss: 0.2819 - val_accuracy: 0.6984\n",
            "Epoch 103/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2759 - accuracy: 0.7046 - val_loss: 0.2855 - val_accuracy: 0.6925\n",
            "Epoch 104/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2761 - accuracy: 0.7045 - val_loss: 0.2829 - val_accuracy: 0.6972\n",
            "Epoch 105/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2758 - accuracy: 0.7043 - val_loss: 0.2826 - val_accuracy: 0.6963\n",
            "Epoch 106/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2757 - accuracy: 0.7044 - val_loss: 0.2821 - val_accuracy: 0.6949\n",
            "Epoch 107/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2758 - accuracy: 0.7045 - val_loss: 0.2850 - val_accuracy: 0.6933\n",
            "Epoch 108/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2760 - accuracy: 0.7039 - val_loss: 0.2827 - val_accuracy: 0.6943\n",
            "Epoch 109/200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2760 - accuracy: 0.7039 - val_loss: 0.2831 - val_accuracy: 0.6986\n",
            "Epoch 110/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2761 - accuracy: 0.7046 - val_loss: 0.2825 - val_accuracy: 0.6951\n",
            "Epoch 111/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2759 - accuracy: 0.7039 - val_loss: 0.2830 - val_accuracy: 0.6950\n",
            "Epoch 112/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2759 - accuracy: 0.7038 - val_loss: 0.2820 - val_accuracy: 0.6960\n",
            "Epoch 113/200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2763 - accuracy: 0.7048 - val_loss: 0.2838 - val_accuracy: 0.6967\n",
            "Epoch 114/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2758 - accuracy: 0.7046 - val_loss: 0.2836 - val_accuracy: 0.6950\n",
            "Epoch 115/200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2759 - accuracy: 0.7053 - val_loss: 0.2819 - val_accuracy: 0.6977\n",
            "Epoch 116/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2760 - accuracy: 0.7046 - val_loss: 0.2824 - val_accuracy: 0.6987\n",
            "Epoch 117/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2760 - accuracy: 0.7044 - val_loss: 0.2844 - val_accuracy: 0.6939\n",
            "Epoch 118/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2755 - accuracy: 0.7037 - val_loss: 0.2822 - val_accuracy: 0.6950\n",
            "Epoch 119/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2763 - accuracy: 0.7047 - val_loss: 0.2845 - val_accuracy: 0.6942\n",
            "Epoch 120/200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2761 - accuracy: 0.7034 - val_loss: 0.2841 - val_accuracy: 0.6941\n",
            "Epoch 121/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2758 - accuracy: 0.7042 - val_loss: 0.2838 - val_accuracy: 0.6933\n",
            "Epoch 122/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2760 - accuracy: 0.7036 - val_loss: 0.2823 - val_accuracy: 0.6956\n",
            "Epoch 123/200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2758 - accuracy: 0.7055 - val_loss: 0.2838 - val_accuracy: 0.6939\n",
            "Epoch 124/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2758 - accuracy: 0.7039 - val_loss: 0.2839 - val_accuracy: 0.6916\n",
            "Epoch 125/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2759 - accuracy: 0.7045 - val_loss: 0.2826 - val_accuracy: 0.6978\n",
            "Epoch 126/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2759 - accuracy: 0.7051 - val_loss: 0.2837 - val_accuracy: 0.6972\n",
            "Epoch 127/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2757 - accuracy: 0.7048 - val_loss: 0.2830 - val_accuracy: 0.6958\n",
            "Epoch 128/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2754 - accuracy: 0.7046 - val_loss: 0.2828 - val_accuracy: 0.6964\n",
            "Epoch 129/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2758 - accuracy: 0.7043 - val_loss: 0.2828 - val_accuracy: 0.6951\n",
            "Epoch 130/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2757 - accuracy: 0.7043 - val_loss: 0.2824 - val_accuracy: 0.6964\n",
            "Epoch 131/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2754 - accuracy: 0.7046 - val_loss: 0.2840 - val_accuracy: 0.6968\n",
            "Epoch 132/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2759 - accuracy: 0.7036 - val_loss: 0.2826 - val_accuracy: 0.6969\n",
            "Epoch 133/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2760 - accuracy: 0.7049 - val_loss: 0.2826 - val_accuracy: 0.6956\n",
            "Epoch 134/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2759 - accuracy: 0.7039 - val_loss: 0.2823 - val_accuracy: 0.6999\n",
            "Epoch 135/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2761 - accuracy: 0.7040 - val_loss: 0.2816 - val_accuracy: 0.6973\n",
            "Epoch 136/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2757 - accuracy: 0.7040 - val_loss: 0.2836 - val_accuracy: 0.6954\n",
            "Epoch 137/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2759 - accuracy: 0.7038 - val_loss: 0.2820 - val_accuracy: 0.6969\n",
            "Epoch 138/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2760 - accuracy: 0.7033 - val_loss: 0.2819 - val_accuracy: 0.6987\n",
            "Epoch 139/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2759 - accuracy: 0.7034 - val_loss: 0.2832 - val_accuracy: 0.6945\n",
            "Epoch 140/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2756 - accuracy: 0.7049 - val_loss: 0.2823 - val_accuracy: 0.6942\n",
            "Epoch 141/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2758 - accuracy: 0.7039 - val_loss: 0.2822 - val_accuracy: 0.6945\n",
            "Epoch 142/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2756 - accuracy: 0.7041 - val_loss: 0.2830 - val_accuracy: 0.6963\n",
            "Epoch 143/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2757 - accuracy: 0.7050 - val_loss: 0.2814 - val_accuracy: 0.6975\n",
            "Epoch 144/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2757 - accuracy: 0.7044 - val_loss: 0.2824 - val_accuracy: 0.6964\n",
            "Epoch 145/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2755 - accuracy: 0.7038 - val_loss: 0.2829 - val_accuracy: 0.6976\n",
            "Epoch 146/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2755 - accuracy: 0.7052 - val_loss: 0.2823 - val_accuracy: 0.6958\n",
            "Epoch 147/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2751 - accuracy: 0.7046 - val_loss: 0.2820 - val_accuracy: 0.6992\n",
            "Epoch 148/200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2757 - accuracy: 0.7053 - val_loss: 0.2827 - val_accuracy: 0.6949\n",
            "Epoch 149/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2758 - accuracy: 0.7051 - val_loss: 0.2855 - val_accuracy: 0.6911\n",
            "Epoch 150/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2757 - accuracy: 0.7049 - val_loss: 0.2839 - val_accuracy: 0.6965\n",
            "Epoch 151/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2759 - accuracy: 0.7047 - val_loss: 0.2824 - val_accuracy: 0.6959\n",
            "Epoch 152/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2755 - accuracy: 0.7046 - val_loss: 0.2827 - val_accuracy: 0.6954\n",
            "Epoch 153/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2757 - accuracy: 0.7050 - val_loss: 0.2832 - val_accuracy: 0.6948\n",
            "Epoch 154/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2757 - accuracy: 0.7054 - val_loss: 0.2836 - val_accuracy: 0.6948\n",
            "Epoch 155/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2757 - accuracy: 0.7053 - val_loss: 0.2836 - val_accuracy: 0.6982\n",
            "Epoch 156/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2759 - accuracy: 0.7047 - val_loss: 0.2822 - val_accuracy: 0.6973\n",
            "Epoch 157/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2756 - accuracy: 0.7044 - val_loss: 0.2831 - val_accuracy: 0.6971\n",
            "Epoch 158/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2757 - accuracy: 0.7048 - val_loss: 0.2822 - val_accuracy: 0.6978\n",
            "Epoch 159/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2756 - accuracy: 0.7048 - val_loss: 0.2822 - val_accuracy: 0.6969\n",
            "Epoch 160/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2754 - accuracy: 0.7039 - val_loss: 0.2832 - val_accuracy: 0.6967\n",
            "Epoch 161/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2759 - accuracy: 0.7044 - val_loss: 0.2826 - val_accuracy: 0.6961\n",
            "Epoch 162/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2756 - accuracy: 0.7034 - val_loss: 0.2831 - val_accuracy: 0.6975\n",
            "Epoch 163/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2755 - accuracy: 0.7044 - val_loss: 0.2818 - val_accuracy: 0.6972\n",
            "Epoch 164/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2757 - accuracy: 0.7043 - val_loss: 0.2882 - val_accuracy: 0.6949\n",
            "Epoch 165/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2759 - accuracy: 0.7050 - val_loss: 0.2863 - val_accuracy: 0.6927\n",
            "Epoch 166/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2760 - accuracy: 0.7042 - val_loss: 0.2835 - val_accuracy: 0.6982\n",
            "Epoch 167/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2756 - accuracy: 0.7050 - val_loss: 0.2825 - val_accuracy: 0.6951\n",
            "Epoch 168/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2756 - accuracy: 0.7061 - val_loss: 0.2841 - val_accuracy: 0.6962\n",
            "Epoch 169/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2758 - accuracy: 0.7044 - val_loss: 0.2836 - val_accuracy: 0.6967\n",
            "Epoch 170/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2757 - accuracy: 0.7049 - val_loss: 0.2819 - val_accuracy: 0.6979\n",
            "Epoch 171/200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2755 - accuracy: 0.7051 - val_loss: 0.2822 - val_accuracy: 0.6961\n",
            "Epoch 172/200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2756 - accuracy: 0.7047 - val_loss: 0.2831 - val_accuracy: 0.6969\n",
            "Epoch 173/200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2754 - accuracy: 0.7042 - val_loss: 0.2841 - val_accuracy: 0.6954\n",
            "Epoch 174/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2757 - accuracy: 0.7051 - val_loss: 0.2818 - val_accuracy: 0.6961\n",
            "Epoch 175/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2755 - accuracy: 0.7043 - val_loss: 0.2839 - val_accuracy: 0.6948\n",
            "Epoch 176/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2753 - accuracy: 0.7059 - val_loss: 0.2833 - val_accuracy: 0.6935\n",
            "Epoch 177/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2756 - accuracy: 0.7040 - val_loss: 0.2827 - val_accuracy: 0.6970\n",
            "Epoch 178/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2756 - accuracy: 0.7041 - val_loss: 0.2829 - val_accuracy: 0.6973\n",
            "Epoch 179/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2757 - accuracy: 0.7046 - val_loss: 0.2830 - val_accuracy: 0.6950\n",
            "Epoch 180/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2758 - accuracy: 0.7052 - val_loss: 0.2827 - val_accuracy: 0.6985\n",
            "Epoch 181/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2756 - accuracy: 0.7056 - val_loss: 0.2820 - val_accuracy: 0.6982\n",
            "Epoch 182/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2755 - accuracy: 0.7043 - val_loss: 0.2821 - val_accuracy: 0.6987\n",
            "Epoch 183/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2757 - accuracy: 0.7046 - val_loss: 0.2819 - val_accuracy: 0.6981\n",
            "Epoch 184/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2756 - accuracy: 0.7050 - val_loss: 0.2830 - val_accuracy: 0.6974\n",
            "Epoch 185/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2757 - accuracy: 0.7039 - val_loss: 0.2831 - val_accuracy: 0.6953\n",
            "Epoch 186/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2755 - accuracy: 0.7046 - val_loss: 0.2827 - val_accuracy: 0.6946\n",
            "Epoch 187/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2754 - accuracy: 0.7056 - val_loss: 0.2836 - val_accuracy: 0.6969\n",
            "Epoch 188/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2756 - accuracy: 0.7041 - val_loss: 0.2830 - val_accuracy: 0.6964\n",
            "Epoch 189/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2757 - accuracy: 0.7050 - val_loss: 0.2829 - val_accuracy: 0.6947\n",
            "Epoch 190/200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2752 - accuracy: 0.7047 - val_loss: 0.2824 - val_accuracy: 0.6964\n",
            "Epoch 191/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2756 - accuracy: 0.7050 - val_loss: 0.2836 - val_accuracy: 0.6966\n",
            "Epoch 192/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2751 - accuracy: 0.7047 - val_loss: 0.2819 - val_accuracy: 0.6959\n",
            "Epoch 193/200\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2753 - accuracy: 0.7039 - val_loss: 0.2843 - val_accuracy: 0.6979\n",
            "Epoch 194/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2756 - accuracy: 0.7050 - val_loss: 0.2820 - val_accuracy: 0.6969\n",
            "Epoch 195/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2751 - accuracy: 0.7060 - val_loss: 0.2826 - val_accuracy: 0.6960\n",
            "Epoch 196/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2755 - accuracy: 0.7042 - val_loss: 0.2821 - val_accuracy: 0.6960\n",
            "Epoch 197/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2756 - accuracy: 0.7046 - val_loss: 0.2827 - val_accuracy: 0.6953\n",
            "Epoch 198/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2753 - accuracy: 0.7049 - val_loss: 0.2827 - val_accuracy: 0.6974\n",
            "Epoch 199/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2755 - accuracy: 0.7055 - val_loss: 0.2821 - val_accuracy: 0.6958\n",
            "Epoch 200/200\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2756 - accuracy: 0.7048 - val_loss: 0.2824 - val_accuracy: 0.6995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCf7i0EQaGnI"
      },
      "source": [
        "Can't see to get past accuracy 70% just using simple dense layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nus1dIMv3wtq",
        "outputId": "216a270e-4e73-4fef-adca-d40c699824a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "y_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2173, 5), dtype=float32, numpy=\n",
              "array([[0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OviUiJ91xOGN",
        "outputId": "c9b6e64f-eb0c-46ac-c3cd-6bed92bc1b8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "score=model.evaluate(np.array(x_test_pad),np.array(y_test), batch_size=1024, verbose=1)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8246 - accuracy: 0.6957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxNjgw-GxvPW",
        "outputId": "aa3633e4-923a-4dba-b8cf-ab83a4a9fa34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"model accuracy:\",score[1])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model accuracy: 0.6957007646560669\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djux-NpUz7Ji",
        "outputId": "fe28dbfd-e277-42b3-c3ff-9d3b1a4b0d10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "x = np.expand_dims(x_test_pad[0], axis=0)\n",
        "x.shape\n",
        "model.predict(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.03021459, 0.9041168 , 0.01275015, 0.02538419, 0.02753435]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwr6KqFB5y0I",
        "outputId": "00db1cbd-ee87-40aa-8a02-a4edc4b24da1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>name</th>\n",
              "      <th>time</th>\n",
              "      <th>text</th>\n",
              "      <th>file</th>\n",
              "      <th>cat_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>1611</td>\n",
              "      <td>Bernie Sanders</td>\n",
              "      <td>15:03</td>\n",
              "      <td>Donald Trump and the Republican leadership are...</td>\n",
              "      <td>Bernie Sanders Los Angeles Rally Transcript Be...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5780</th>\n",
              "      <td>10213</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>56:15</td>\n",
              "      <td>But we got more money than they asked for and ...</td>\n",
              "      <td>Donald Trump ‘Black Economic Empowerment’ Spee...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>183</td>\n",
              "      <td>Joe Biden</td>\n",
              "      <td>01:07:49</td>\n",
              "      <td>The future really rests on investment. We’re g...</td>\n",
              "      <td>2020 Democratic National Convention (DNC) Nigh...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4229</th>\n",
              "      <td>8328</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>01:13:28</td>\n",
              "      <td>We’ll strongly protect Medicare and Social Sec...</td>\n",
              "      <td>Donald Trump Newport News, Virginia Campaign R...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1992</th>\n",
              "      <td>5235</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>01:13:48</td>\n",
              "      <td>But if you’re not requesting them, when you ge...</td>\n",
              "      <td>Donald Trump Campaign Speech Transcript Vandal...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ... cat_num\n",
              "296         1611  ...       0\n",
              "5780       10213  ...       3\n",
              "18           183  ...       1\n",
              "4229        8328  ...       3\n",
              "1992        5235  ...       3\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfTCfPNA6BNO",
        "outputId": "6f31f4b3-1f18-4a27-f3fa-2a065d2b1c93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_test[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([1., 0., 0., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDHwAC03z-wx"
      },
      "source": [
        "model.save_weights(\"/content/drive/My Drive/Machine Learning/news_lstm_1.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEqsHugNvTk0"
      },
      "source": [
        "def predict(text):\n",
        "  text = [text]\n",
        "  seq = t.texts_to_sequences(text)\n",
        "  text_arr = pad_sequences(maxlen=max_len, sequences=seq, padding=\"post\", value=0)\n",
        "  print(text_arr)\n",
        "  text_arr.shape\n",
        "  return model.predict(text_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLCE4ALhvwtU",
        "outputId": "ba8a8cd4-c2e5-426e-f525-211987f608e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "results = predict(\"Rubio Has A Rocky Road Ahead\t!\")\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 999   58    4 6964  664  821    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "[[1.8750572e-07 6.7876118e-07 2.6042713e-04 3.9953052e-04 3.4411922e-05\n",
            "  6.7518355e-04 5.7862457e-05 2.0026339e-06 1.2046334e-07 3.4730008e-05\n",
            "  2.9307179e-04 1.7206936e-07 1.9639631e-06 4.7070738e-09 1.3729482e-07\n",
            "  3.8334758e-05 1.7999735e-04 1.6748100e-08 3.2059750e-05 7.9951606e-05\n",
            "  4.2417888e-03 1.1336841e-06 2.2617862e-06 1.2134593e-06 9.9218643e-01\n",
            "  3.4863144e-05 9.9452533e-05 1.6575746e-06 1.1835338e-05 1.2320362e-06\n",
            "  1.0100941e-06 2.8239212e-08 1.6465271e-04 1.2510394e-04 2.1267982e-05\n",
            "  5.5921556e-09 5.5196078e-06 9.1133530e-05 3.3647133e-04 1.5436081e-04\n",
            "  4.2773102e-04]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8M2vIJBwTEK",
        "outputId": "15659c00-f82f-4258-f60d-2eb92b94144a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "arg=np.argmax(results)\n",
        "print(arg)\n",
        "print(results[0][arg])\n",
        "print(arg_max_label[arg])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24\n",
            "0.9921864\n",
            "POLITICS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZDvs9TjaGDb",
        "outputId": "73ceb0d5-609c-41fb-db25-695e8706e1dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "24]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'WORLD NEWS'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emDnBwP9aIyN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}